**观前提醒：如果只是想了解个大概可以不用看斜体部分（虽然也很简单）**

# 什么是无监督学习？

用于学习的数据没有任何标记，机器完全不知道是什么

## 先问什么是学习

- 学习的本质是举一反三：以高考为例，高考的题目在上考场前我们未必做过，但在高中三年我们做过很多很多题目，懂解题方法，因此考场上面对陌生问题也可以算出答案
- 还原到深度学习训练模型：我们能不能利用一些训练数据（已经做过的题），使机器能够利用它们（解题方法）分析未知数据（高考的题目）
- 因此这个有无监督是针对于**训练算法的模型**（教做题家的老师）的，而不是训练出的算法本身（真正做题的学生）

## 无监督学习是干嘛的

我们就拿训练分类算法的模型来举例。

- 什么是分类？就是已知Label和Feature，**找出描述Label和Feature关系的函数**。
  - 但是，打标签多累啊，谁想打标签，这种重复机械的工作就该交给机器做

- 那无监督学习分类算法不就来了吗？已知Feature但没有Label，通过已有的关系得到未知数据标签 
  - 我们把无监督分类又叫聚类算法
  - 为什么叫聚类呢？因为我们完全不监督，就是一个标签也没有，机器也不知道我们想要什么，他只能觉得哪些长得像就放在一堆
  - 无监督分类（聚类算法）的特征
    - 无法预知结果，可用性可能较低
    - 可以统计地从完全没有标签的数据中发现新的潜在结构（比如可以发现洗钱这种小规模异常行为）

#### 有没有办法有方向又不用打标签呢

那肯定是有的，就是**半监督学习**（无标签的数据远大于有标签的数据）

- 为什么可以呢？
  - 真实数据的分布肯定不是随机的
  - 可以基于有标签部分的结构推测全体数据结构，优化完全无监督学习的结果

### 常见的无监督学习算法应用

先看无监督学习两种最常见的应用

- 降维：提取有效信息，删除无效信息
- 聚类（刚刚讲过了）：所有算法均假设：数据点已经预先分布在了向量空间中
  - *K均值聚类*
    - *先随机定义K个重心（或者其他算法）*
    - *每个数据点分配给最近的重心*
    - *将重心移动到聚类的中心，再重新上述步骤，直到重心位置不再变化*
  - *层次聚类：不知道多少类*
    - *每个数据点分配一个聚类*
    - *将彼此最近的两个聚类合并*
    - *重新计算，重复上述步骤，直到收缩到想要的类别数量*

## 来看几个经典模型

说了这么多，那来看看模型吧。

首先呢，这个无监督学习分为两个大类：生成学习和对比学习

<img src="C:/Users/kirito/AppData/Roaming/Typora/typora-user-images/image-20220413183724926.png" alt="image-20220413183724926" style="zoom: 67%;" />

知己知彼，百战不殆，今天要讲对比学习，那就首先从**生成学习**里挑一个大家最熟悉的来讲

### 生成对抗网络 GAN

无监督学习要一堆没有标签的数据，哪里来呢？这不简单，自己造呗。

GAN就训练了一个算法来生成自己的数据实例。

<img src="https://pic2.zhimg.com/v2-8e747f48105e3507e9d64c2faaab78ad_r.jpg" alt="img" style="zoom:50%;" />

- *可以视为生成一个满足要求的DECODER（反向的ENCODER）*

  - *Discriminator: 计算生成器的LOSS函数，反馈训练Generator*
  - *Generator：随机生成图片向量，目的使训练Discriminator*

- *G想要最小化D的输出，而D想要最大化D的输出，因此“对抗”*

  - *G通过的图像数量越大，得分越高*

  - *D发现的假图数量越大，得分越高*

先不慌看这个模型在干嘛，我们先高屋建瓴地看一下生成模型的特点，尤其是和对比模型的不同点。

仔细看我们这个模型最后训练出来的东西干了啥？G生成了一张图，D判断后还是输出了一张图。生成模型和对比模型最大的区别就在这了，我输进去一个啥，他出来还是一个啥，至少类型还是一样的。

至于GAN具体实现什么，我们也不用管了，反正我们现在也用不上他。

再举一个生成模型的例子：自动编码器。

我们也不用管具体长什么样，只需要知道他把元数据经过一个ENCODER->LATENT VECTOR->DECODER的过程，把原数据降噪了，降维了就可以。发现了吗，还是进去是啥就出来是啥。

### 对比学习又是啥呢

说了这么久终于说到正题了，还是老样子，先问一个问题。

#### 什么是对比，对比能干啥

回想一下生成学习，是不是输进去**一个**东西，出来的还是这个东西。

没错，可我们如果最终只是想分个类，我也没有必要处理他啊，有没有办法只分这个类而不生成其他的东西呢。

对比，就是单纯地看看两个像不像，就不做其他工作了，不是很完美？

### 小小的总结一下

因此我们总结一下，生成就是输出一个Key Feature，LOSS计算自然也是在OUTPUT以后完成的；而对比则是直接比较两个之间像不像，在比较的时候就完成了LOSS的计算，输出的是一个Binary Value（同类或者不同类）

