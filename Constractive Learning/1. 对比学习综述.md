前排提醒：本文不是一篇严谨的综述，只说大白话！严谨综述请移步下面的参考文献！

前置声明：为了区分，下文中模型是指训练用的代码（如GAN），算法是指训练得到的结果（如Generator）

参考：[对比学习（Contrastive Learning）综述](https://zhuanlan.zhihu.com/p/346686467)



---

# 前情提要

对于深度学习所用数据，根据标记与否可以分为**监督学习**和**无监督学习**两种

- 监督学习：所有数据标记，直接学习

- 无监督学习：数据没有标记，但可以自己创造标记来学习
- 半监督学习：有一些数据有标记，给没有标记的数据指明了方向

### 无监督学习的两种方式

- 生成式学习：以Auto-Encoder为代表，对数据进行降维，输出的仍然是数据
- 对比式学习（Constrastive Learning）：以SimCLR，CPC和MOCO为代表，对数据进行分类
  - 不需要关注实例中繁琐的细节，只需要在抽象语义级别的特征空间上学会对数据的区分
  - 学习目标仍是一个**编码器**，对同类数据进行相似的编码，并使不同类的数据的编码结果尽可能不同



# 聊一个前置概念：表征学习

参考文献：

- [什么是Representation Learning？ - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/136554341)
- [表示学习(representation learning)初印象 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/112849395)

为什么要讨论他，只因他和无监督学习的大概念确实容易混淆，在这里先**做一个区分**。

表征学习（**representation learning**），是一种**技术的集合**，并不是某一个特定的技术，有很多类型和模型。他和其他的学习类型也不是完全无交集的关系。

其作用是将原始数据转换成为能够被机器学习利用的形式，即**从无到有提取出数据的特征**，来服务于机器学习（替代原本人为设计的特征）。

<img src="https://pic3.zhimg.com/v2-b2e25a17bb1c8777438aaa28587ed6e6_r.jpg" alt="img" style="zoom:67%;" />

我们回到机器学习和高考做题的例子（区分有无监督学习）：

- 在普遍的机器学习中，模型（老师）利用数据中的已有的特征（老师划好的考纲）来训练算法（学生）
- 特征学习的作用就是**提取数据的特征（划定考纲）**，取代人为设计的过程

#### 特征学习有什么用呢？

我们先举一个特征学习的典型方法：**自编码器**。大家是不是有想法了？

自编码器是干嘛的？提取数据关键特征对吧，这不是豁然开朗了？

这不就和之前说过的无监督学习扯上关系了，它可以作为数据预处理手段，**为无监督/半监督学习**提供一种实现方法。

虽然表征学习也有有监督和无监督的区别，但是**表征学习的有无监督对我后续的机器学习有无监督是独立的，它只是一种数据预处理手段**。

一句话总结：**数据预处理手段**，所以我们是不是可以用于对比学习的初始向量空间构建呢，这里的可行性后面再讨论。

#### 重点：区分标签和特征

标签“Label”是对答案的人为评定，特征“Representation”是对元数据的信息提取。

在分类工作中，Label可以近似等同于Representation，因为分类工作的答案就是Representation（分类依据）



----



# 对比学习究竟是什么

话不多说，先上一张图，我最讨厌一上来就摆概念了，像国内的教科书一样。

一种经典的对比学习模型图如下（来自于SimCLR模型）

先不用细看，后面再解释。

<img src="https://pic4.zhimg.com/v2-a17404a49d4f980ac69653464dbcc3fb_r.jpg" alt="img" style="zoom: 50%;" />

## 对比学习到底是怎么做的

要知道我们要怎么做，首先得知道我们要做什么：**对比学习目的是什么？**

得到编码器，对吧？然后呢？

我们要让编码器对不同的特征的编码尽量不同，换句话说还是**分类**

先举一个二元分类的例子，假设一堆人要交朋友，这些人有的人是XZ粉，他们不和别的人玩，那要怎么划这个圈子最稳定呢？那就是XZ粉聚成一堆，其他人聚成一堆，而且彼此之间隔的尽量远。

这就是对比学习中最核心的思想：

- 两个人如果都是/都不是粉丝（**极性相同**）称为正样本，就是我这个模型训练的编码器他觉得你们是同一类的就是正样本，否则就是负样本 —— 我们把这个极性称为Y（假设相同时为0，不同时为1）
- 我们需要保证两个不同团体之间隔得**尽量远（有效分类）**，这就是我这个模型对编码器的**评分标准（LOSS函数）**

因此我们说得数学一点，对比学习模型训练出的编码器就是**在给定锚点（向量固定）的情况下对坐标空间进行变换，使正样本之间尽可能近，负样本之间尽可能远。**

<img src="https://pic2.zhimg.com/v2-7f0cb4f5a90df300585de6e24a516bad_r.jpg" alt="img" style="zoom:67%;" />

从上面的例子中我们可以读出几个问题：

1. 向量和空间怎么定义（**如何定义目标函数**）
2. 怎么确定两个样本是正还是负（**如何构建正负样本对**）
3. 如何判定两个向量的距离是否足够远/近（**如何定义LOSS函数**）





# 一个简化的例子

我们先从最后一个问题入手（doge），~~因为他最简单~~同时对其他两个问题做简化处理（抽象已知）

- 假设我们已经完成了向量建模（目标函数已经定义），并且已经得到了正负样本对
- 为什么要这么做呢？不同场景下其他两个问题区别较大，而**LOSS函数的核心思想几乎不变**，可以说理解了LOSS函数的设置就理解了对比学习的大半

我们先看上面对相似度的定义，我们要的最直接的结果是啥，是样本之间的距离。

距离嘛，那我们就选一个最直接的，欧几里得距离，直线，够简单直接！

<img src="https://picgo-1308055782.cos.ap-chengdu.myqcloud.com/typora-bed/%20image-20220413195733541.png" alt="image-20220413195733541" style="zoom: 50%;" />

但是损失可不是只定义一个距离就完了的，毕竟我们又不是只求一对向量的距离，而是所有向量，包括了正样本和负样本的所有向量。

因此，我们还要做亿点小小的修正。

先把公式摆出来，大家先不要慌，我慢慢说。

<img src="https://picgo-1308055782.cos.ap-chengdu.myqcloud.com/typora-bed/%20image-20220413195838923.png" alt="image-20220413195838923" style="zoom:50%;" />

**【这部分直接画图讲】**

我们先回顾一下初中物理，弹性势能的公式大家都知道吧。

当它大于原长的时候随着弹簧越来越长，他的弹性势能会越来越大；小于原长时，压缩弹簧，弹性势能也会越来越大。这显然不能作为我们的度量函数，这分明就是在说你就呆在原长最好，不能做到聚类的效果。

我们再对弹性势能的公式做一点小小的取舍。

这**正样本**的时候呢，我们应该是越近越好吧，那么把E作为LOSS的话就是E越小越好。划重点，**正样本时，E越小越好。**再做一点理想的假设，即原长为0，就得到了下面的公式。

<img src="https://picgo-1308055782.cos.ap-chengdu.myqcloud.com/typora-bed/%20image-20220413200404803.png" alt="image-20220413200404803" style="zoom:50%;" />

那么负样本呢？既然要越远越好，那么就要**离得越近LOSS就要越大**。套用到E中不就是压缩时的弹性势能吗？那原长呢？只能我们自己定义了，我们定义一个m，说只要大于这个m就够远了，看不见了，也不管你以后伸长还是啥了，与我无关了。

<img src="https://picgo-1308055782.cos.ap-chengdu.myqcloud.com/typora-bed/%20image-20220413200630322.png" alt="image-20220413200630322" style="zoom:50%;" />

这时我们再代回上面的公式，注意啊，这个LS和LD可不是参数，他可是函数。

<img src="https://picgo-1308055782.cos.ap-chengdu.myqcloud.com/typora-bed/%20image-20220413200726933.png" alt="image-20220413200726933" style="zoom:50%;" />

<img src="https://picgo-1308055782.cos.ap-chengdu.myqcloud.com/typora-bed/%20image-20220413200738208.png" alt="image-20220413200738208" style="zoom:50%;" />

其他的参数比如那个W（网络权重），我们暂时用不到它，就先按下不表，如果需要根据多个表来分类的话就需要用到这个参数。

至此，最基本的Loss函数定义就被我们求得了：

<img src="https://picgo-1308055782.cos.ap-chengdu.myqcloud.com/typora-bed/%20image-20220413201030765.png" alt="image-20220413201030765" style="zoom:50%;" />

上面的模型会根据这个LOSS函数进行调参，如果Y=0（同类）就让E最小，如果Y=1（不同类）就把它移到m以外的空间去（如果已经在外面就不管），直至整个系统能量最低为止。



---



# 一些经典的CL模型

我们已经初步了解了LOSS函数，但是其他的问题就不能这么抽象地说了，是时候来点具体模型和例子了。

## 1. SimCLR模型

这真的是一个非常经典的模型，也是本节唯一详细论述的模型，是CL在CV（计算机视觉）领域的经典运用，刚推出直接用无监督学习屠榜了所有有监督学习。

不过在正式进入这个模型之前，先让我们忘掉有些愚蠢的欧式距离和弹性势能模型，只需要记住这一句话：**越像的靠得越近**（这个近是抽象意义上的近）。

然后，我们就正式开始吧。

老规矩，我们先上一张图，这是SimCLR模型的真正结构，如果你有兴趣的话可以倒回去看一下最开始的第一张图~~（虽然完全没有必要）~~

一样的，我们先不深究细节，一步步来。

<img src="https://pic4.zhimg.com/v2-a64b94ff65e2c03598ddfc5fe41dd57f_b.jpg" alt="img" style="zoom:67%;" />

在S模型中，我们的对比学习（无监督学习）只用作了第一阶段 - 预训练，也就是先从零开始训练一个初步可用的模型。

这个预训练的模型可以迁移学习（运用已有的知识来学习新的知识，核心是找到已有知识和新知识之间的相似性），即后续再用这个预训练的模型，加上具体任务，用带标签的数据去训练，就可以得到某一特定的任务的f(*x*)。

而上面这个图，就是描述的对比学习的部分，毕竟后面的我们现在也不关心。



所以回到最初的问题，我们要干嘛？我们要通过对比学习，得到一个可以给图片分类的编码器，换句话说就是得到一个有价值的图片的Representation。~~得了，又是Representation Learning了（因为得到的也是一个提取特征的算法）~~

那我们来看对比学习的三大基本问题：

- 怎么定义向量（目标函数）？
- 怎么定义正负样本？
- 怎么定义损失函数？

我们不按问题的顺序，我们按模型从下往上的顺序去回答这些问题。

### 1）数据增强：定义正负样本

众所周知，我们对比学习是高贵的无监督学习，没有一条数据是有标签（已知特征）的，所以机器压根儿不知道谁是谁，让他直接去比对不同数据来分类那就像让猴子去拼李白的诗一样，纯纯地乱来了。

有没有办法从现有的数据中去造有价值的样本对呢，就是那种形式不一样，但关键特征一样的？

还真有，你看，一条狗它放大了看，倒着看，搁着毛玻璃看，不都是狗吗？但对于机器来说这图就不一样了啊，这不模型的训练素材不久有了吗？

S模型中，我们把这一步称为数据增强，通过数据增强，我们把一张原图就增强到了两张。

数据增强有下面三种方法：

- 随机裁剪之后再resize成原来的大小 (Random cropping followed by resize back to the original size)。
- 随机色彩失真 (Random color distortions)。
- 随机高斯模糊 (Random Gaussian Deblur)

这样，我们不需要外力的帮助，自己就从没有标记的样本里找到了可用的正负样本。

### 2）编码和投影：定义向量和空间

我们现在拿到了可用的正负样本，我们要拿他干嘛呢？

回到对比学习中，我们已经拿到了很多点（样本对）了，就应该把它投到空间里算距离了，这样才能算LOSS才能迭代。

#### Encoder

这个S模型有一个优点，就是他的ENCODER可以随便选，没有任何限制，因此我们可以借用他的壳子套上我们的NLP编码模型也不是不行（当然这都是后话了）

我们就先用它原版的ResNet-50编码器，简单地说就是一个卷积神经网络（CNN），它的功能也是提取出一个图片的Representation，形式是2048维的一个矢量。

还记得我们对比学习的最终目标吗，就是得到Representation，那我们**这个编码器就是我们模型要得到的东西**了，后续迭代也是对它不断地调参，直到可以恰当地表达图片的特征。

这里的Encoder还有一个数学细节，两个增强后的图片是放在一起算的，共同求出彼此的Similarity。

#### Projection Head

拿到向量了，我们就把它投到合适的空间里，这就是投影头的工作。

这里的投影头是一个2层的MLP（多层感知器），它的工作就是将2048维的向量进一步映射到128维隐空间中，得到新的Representation，也是最终参与运算的Representation

### 3）相似度计算：定义LOSS函数

前两部分我们已经得到了所有图片的特征向量。

<img src="https://pic2.zhimg.com/v2-ee028813716f0cb1bca4a23bddad14d9_b.jpg" alt="img" style="zoom: 67%;" />

接下来我们计算他们的余弦相似度

<img src="https://picgo-1308055782.cos.ap-chengdu.myqcloud.com/typora-bed/%20image-20220414005728077.png" alt="image-20220414005728077" style="zoom: 50%;" />

我们现在有了衡量相似度的办法，但是这不够，我们必须得定义LOSS函数才能迭代。

回忆一下，LOSS函数要求越像越小，但这个相似度是越像越大啊。怎么办呢？我们就把相似度取一个负对数再加起来不就行了。

顺着这个思路，我们再补充亿点细节，就得到了S模型的LOSS函数：**NT-Xent loss** (**Normalized Temperature-Scaled Cross-Entropy Loss**，**归一化温度标度的交叉熵损耗**)，大概过程如下：

1. 根据编码器得到的特征向量求出两两之间的余弦相似度
2. 用Softmax函数均一化处理

<img src="https://pic1.zhimg.com/v2-d2fadcdea7ae129c6791f92b49779964_b.jpg" alt="img" style="zoom: 67%;" />

3. 对Softmax的结果取负对数

![image-20220413222240961](https://picgo-1308055782.cos.ap-chengdu.myqcloud.com/typora-bed/%20image-20220413222240961.png)

4. 最后把所有对的LOSS加起来，求平均值就得到了LOSS函数

   <img src="https://picgo-1308055782.cos.ap-chengdu.myqcloud.com/typora-bed/%20image-20220414010311792.png" alt="image-20220414010311792" style="zoom:50%;" />



#### Downstream Task 和 Fine-tune

在投影头一步就分支出去了，不参与对比学习过程，此处不予讨论







## 2. CPC（Contrastive Predictive Coding）模型

CPC的**目标**就是要做unsupervised representation learning，并且我们希望这个representation有很好的predictive的能力

对于高维度，少Label的数据集，可以利用无监督学习获取高级信息

这里的Predict是无监督学习的一种方式，最终目的仍然是分类

- 压缩高维数据到更紧凑的**隐空间（Latent Space）**中，便于建模
  - 隐空间本身只是表示压缩后的数据
  - 隐空间的作用是为了找到一个pattern来存储所有相关信息并忽略噪音，达到降维、压缩的效果
  - 忽略多余信息后，特征相似的点在隐空间中的距离更近
  - 从数据空间映射到隐空间，然后再映射回数据空间就可以实现简单的自动编码器
- 利用**自回归模型（AR，Autoregressive Model）**实现预测
  - 统计上一种处理时间序列的方法，用同一变数例如x的之前各期，亦即**x1至xt-1来预测本期xt的表现**，并假设它们为一线性关系。
  - 因为这是从回归分析中的线性回归发展而来，只是不用x预测y，而是用x预测 x（自己）；所以叫做自回归
- 利用NCE计算Loss
- 对于多模态的数据可以学到高级信息





### 附录1：SimCLR中相关概念

#### ResNet-50

卷积网络（CNN）的一种，重要应用也是CV

？卷积的数学本质是什么

##### 什么是卷积神经网络CNN

注意：典型的 CNN 并非只是上面提到的3层结构，而是多层结构

例如 LeNet-5 的结构有：**卷积层 – 池化层- 卷积层 – 池化层 – 卷积层 – 全连接层**

![全连接层](https://easy-ai.oss-cn-shanghai.aliyuncs.com/2019-06-19-quanlianjie.png)

![LeNet-5网络结构](https://easy-ai.oss-cn-shanghai.aliyuncs.com/2019-06-19-lenet.png)

**CNN要解决什么问题？**

- 「将复杂问题简化」，把大量参数降维成少量参数，再做处理。

**要怎么实现呢？**

- 由于人脑的图像识别也是逐层进行的，模仿人类大脑的这个特点，构造多层的神经网络
- 较低层的识别初级的图像特征，若干底层特征组成更上一层特征，最终通过多个层级的组合，最终在顶层做出分类（信息提取）

##### CNN隐层的结构

- 卷积层：提取图像特征
  - 使用一个过滤器（卷积核）来过滤图像的各个小区域，从而得到这些小区域的特征值
  - **每个卷积核代表了一种图像模式**，如果某个图像块与此卷积核卷积出的值大，则认为此图像块十分接近于此卷积核（这个块可以用这个模式来还原）
- 池化层：降维、防止过拟合
  - 下采样，即降低维度（把原式的块合并成特征图）
  - **不但可以大大减少运算量，还可以有效的避免过拟合**
- 全连接层：输出结果
  - 经过卷积层和池化层处理过的数据输入到全连接层，得到最终想要的结果
  - 经过卷积层和池化层降维过的数据，全连接层才能”跑得动”，不然数据量太大，计算成本高，效率低下

##### 什么是残差网络（Residual Net）

将靠前若干层的某一层数据输出直接跳过多层引入到后面数据层的输入部分，意味着后面的特征层的内容会有一部分由其前面的某一层线性贡献。

![img](https://upload-images.jianshu.io/upload_images/14920577-89b850b1f51d897e.png?imageMogr2/auto-orient/strip|imageView2/2/w/432/format/webp)

**残差网络能做什么？**

- 为了克服由于网络深度加深而产生的学习效率变低与准确率无法有效提升的问题

##### 残差网络的结构

ResNet50有两个基本的块，分别名为Conv Block和Identity Block，

- 池化层：ConvBlock输入和输出的维度是不一样的
  - 不能连续串联
  - 它的作用是改变网络的维度
- 卷积层：IdentityBlock输入维度和输出维度相同，
  - 可以串联
  - 用于加深网络

![img](https://upload-images.jianshu.io/upload_images/14920577-eadf28fb2c2c6eca.png?imageMogr2/auto-orient/strip|imageView2/2/w/278/format/webp)



