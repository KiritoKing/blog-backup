# Dygie++ 模型

模型来自论文 [Entity, Relation, and Event Extraction with Contextualized Span Representations (aclanthology.org)](https://aclanthology.org/D19-1585.pdf)



## 特点

- 有监督学习：使用带标签的数据训练
- 给出的模型代码使用的是预训练的模型
- 从Dygie模型进化而来
- 与BERT模型适应良好，效率比单独使用BERT更高



## Dygie 模型

DYGIE是Dynamic Graph Information Extraction的缩写，是通过动态生成图（Dynamic Span Graph）来实现信息提取（IE）的通用模型框架。

这是一个多任务模型，同时训练NER（命名实体识别），RE（关系提取，在模型中是对Span分配关系类型标签），CS（实体指代消解，Conferrence Solution，在模型中将同一实体的Span合并成一个），因为这三个任务之间具有相关性，可以大幅提高文本信息的利用率

Dygie的Span是从上下文得到的，因此对上下文具有很强的相关性

什么是Span：连续单词序列



模型输入：文档的单词序列D，从D中得到所有可能的单词序列Span（长度为1~L）

模型输出：

- S中所有Span的实体类型E（标签集合）
- 位于同一句子中的所有Span对的关系R
- S中所有跨句Span的共指连接C

因此得到两个基本的任务：**实体识别（得到标签）和关系提取（得到R）**，额外的有监督辅助任务：共指消解

哪里看出来动态生成图：一直在动态生成边，迭代过程也是闭包



![img](https://picgo-1308055782.cos.ap-chengdu.myqcloud.com/typora-bed/%201346871-20210905150052596-555907009.png)



### Token Representation Layer

InputDocument每次输入一个句子，系统对其进行分词得到A，将Glove预训练模型的embedding（预处理结果？）和ELMo的embedding分别作为B和C，然后把A、B、C一起喂给BiLSTM，**把BiLSTM的输出作为Token的Representation**

##### 什么是BiLSTM

参考：[BiLSTM介绍及代码实现 | 机器之心 (jiqizhixin.com)](https://www.jiqizhixin.com/articles/2018-10-24-13)

BiLSTM用于NLP中对句子进行感情分类（褒义还是贬义），**BiLSTM由前向和后向两个LSTM模型组成，用于解决普通LSTM无法编码句子中从后向前的信息的问题**

普通LSTM只能捕捉从前到后的顺序，但无法编码从后到前的信息。如“我不觉得他好”中“不”在前面LSTM就可以分析；但“这个餐厅脏得不行，没有隔壁好”中否定词“不行”在后面，就只能BiLSTM可以处理

### Span Representation Layer

对每个span的si信息依次拼接，得到特征向量gi

- si相邻的左右两个span的end points（结束位置下标）
- Attention算法得到的“Head Word”
- Span的宽度特征

### Coreference Propagation Layer

这一层中解决了**共指消解问题**（跨句子的Span的指向的共同对象），是一个辅助训练任务

邻居是可能的共指前驱

从初始表达gi^0^ 开始，在每次迭代t中

1. 先计算一个更新向量 uc^t^
2. 使用更新向量更新，得到gi^t+1^
3. 重复N次（遍历所有span），这表示共享了所有Span之间的上下文信息

### Relation Propagation Layer

直接用gi^N^作为输入，其迭代过程与共指消解的过程类似，解决关系问题

邻居是句中相关的实体

重复迭代M次

### Final Prediction Layer 

直接用gi^N+M^ 输入来预测实体标签E和关系标签R

- 实体：将gi^N+M^输入给前向神经网络（FNN），生成实体标签匹配分数
- 关系：将实体和关系一起输入给前向神经网络，生成关系匹配分数
- 共指：对共指层的输出进行计算，得到对应匹配分数





## Dygie++模型

Dygie++在Dygie上做了延伸和优化

- EE(Event Extract)作为新的附加任务参与Span更新
- 创建了多聚Bert编码的Span表达

### 工作流程

![image-20220609204902771](https://picgo-1308055782.cos.ap-chengdu.myqcloud.com/typora-bed/%20image-20220609204902771.png)

- 通过**滑窗**的方法把每个句子附近的*L*个句子送进BERT模型，得到Token表示
- 用DyGIE中相同的办法把Token集合枚举出Span
- 图传播（Span Graph Propagation）过程与DyGIE中类似
  - 共指消解
  - 关系传播
  - 事件提取？
    - 邻居是事件触发词结点（谓语）和事件元素结点（主语、宾语）
    - 触发词结点向其可能的元素结点传递消息，元素结点也反过来可以传递消息